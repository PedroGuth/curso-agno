{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧠 Agno 2.0 - Módulo 2: Agentes Básicos - O Cérebro dos Nossos Agentes!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/agno-2.0-framework--modulo-02_img_01.png)\n\nEaí, pessoal! 🚀\n\nNo **Módulo 1**, a gente já criou nosso primeiro agente simples e viu como o Agno funciona. Agora no **Módulo 2**, vamos mergulhar fundo no **cérebro dos nossos agentes**: os **Modelos LLM**!\n\nPensa assim: se o agente fosse um carro, o modelo LLM seria o motor. Sem ele, não rola nada! E assim como você escolhe entre um motor 1.0 econômico ou um V8 turbo, você também pode escolher entre diferentes modelos de IA para seus agentes.\n\n## 🎯 O que vamos aprender hoje:\n\n1. **Modelos LLM**: GPT, Claude, Gemini e mais\n2. **Instruções**: Como \"programar\" nossos agentes\n3. **Roles**: Definindo personalidades\n4. **Configurações**: Ajustes finos para performance\n5. **Context Engineering**: A arte de escrever prompts perfeitos\n\n**Dica!** 💡 Vamos usar o **Gemini 2.0 Flash** da Google porque é **gratuito** e muito bom para aprender!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤔 Tá, mas o que são Modelos LLM mesmo?\n\n**LLM** = **Large Language Model** (Modelo de Linguagem Grande)\n\nÉ como se fosse o **cérebro artificial** que entende e gera texto. Imagina que você tem um amigo super inteligente que:\n- Leu praticamente toda a internet\n- Entende múltiplas linguagens\n- Consegue raciocinar sobre qualquer assunto\n- Nunca fica cansado\n\nEsse é o LLM! 🧠\n\n### Os Principais Players do Mercado:\n\n| Modelo | Empresa | Características | Preço |\n|--------|---------|-----------------|-------|\n| **GPT-4o** | OpenAI | Mais inteligente, multimodal | 💰💰💰 |\n| **Claude 3.7 Sonnet** | Anthropic | Excelente para análise, ético | 💰💰 |\n| **Gemini 2.0 Flash** | Google | Rápido, gratuito, muito bom | 🆓 |\n| **Llama 3** | Meta | Open source, roda local | 🆓 |\n\n**Dica!** 💡 Para estudar, sempre use modelos gratuitos como o Gemini. Para produção, aí você investe nos pagos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 Bora configurar nosso ambiente!\n",
        "# Primeiro, vamos instalar o Agno (se ainda não tiver)\n",
        "\n",
        "!pip install agno google-genai -q\n",
        "\n",
        "print(\"✅ Agno instalado com sucesso!\")\n",
        "print(\"✅ Google GenAI instalado com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔑 Configuração da API Key do Google\n",
        "# Vá em: https://aistudio.google.com/apikey\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Se você já tem a key como variável de ambiente, pode pular essa parte\n",
        "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
        "    api_key = getpass(\"🔑 Digite sua API Key do Google AI Studio: \")\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "    print(\"✅ API Key configurada!\")\n",
        "else:\n",
        "    print(\"✅ API Key já configurada!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏗️ Construindo nosso Primeiro Agente com Modelo\n\nAgora que temos tudo configurado, vamos criar nosso primeiro agente usando o **Gemini 2.0 Flash**!\n\nÉ como montar um carro: primeiro escolhemos o motor (modelo), depois configuramos o resto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🤖 Nosso primeiro agente com modelo específico\n",
        "\n",
        "from agno.agent import Agent\n",
        "from agno.models.google.gemini import Gemini\n",
        "\n",
        "# Criando o modelo\n",
        "modelo_gemini = Gemini(id=\"gemini-2.0-flash\")\n",
        "\n",
        "# Criando o agente\n",
        "agente_basico = Agent(\n",
        "    model=modelo_gemini,\n",
        "    name=\"Assistente Brasileiro\",\n",
        "    description=\"Um assistente amigável que fala como brasileiro\"\n",
        ")\n",
        "\n",
        "# Testando nosso agente\n",
        "print(\"🤖 Agente criado! Vamos conversar...\")\n",
        "agente_basico.print_response(\"Oi! Como você está?\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎭 O Poder das Instruções - Programando a Personalidade\n\nLembra quando você era criança e brincava de \"faz de conta\"? \n\n- \"Agora você é um médico!\"\n- \"Agora você é um professor!\"\n- \"Agora você é um pirata!\"\n\nCom agentes de IA é **exatamente** a mesma coisa! As **instruções** são como você diz para o agente: \"Agora você é um...\"\n\n### Anatomia de uma Boa Instrução:\n\n1. **Papel/Role**: Quem o agente é\n2. **Contexto**: Onde ele está\n3. **Objetivo**: O que ele deve fazer\n4. **Tom**: Como ele deve falar\n5. **Restrições**: O que ele NÃO deve fazer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 👨‍🍳 Criando um Chef Brasileiro\n",
        "\n",
        "chef_brasileiro = Agent(\n",
        "    model=Gemini(id=\"gemini-2.0-flash\"),\n",
        "    name=\"Chef Brasileiro\",\n",
        "    \n",
        "    # 📝 Aqui estão as instruções detalhadas\n",
        "    instructions=[\n",
        "        \"Você é um chef brasileiro experiente e carismático\",\n",
        "        \"Você tem 20 anos de experiência na culinária brasileira\",\n",
        "        \"Fale de forma calorosa e amigável, como um tio querido\",\n",
        "        \"Use gírias brasileiras naturalmente (ex: 'cara', 'mano', 'né')\",\n",
        "        \"Sempre sugira ingredientes fáceis de encontrar no Brasil\",\n",
        "        \"Se não souber uma receita, seja honesto e sugira alternativas\",\n",
        "        \"Inclua dicas práticas e truques de cozinha\"\n",
        "    ],\n",
        "    \n",
        "    markdown=True  # Para formatar melhor a resposta\n",
        ")\n",
        "\n",
        "print(\"👨‍🍳 Chef brasileiro pronto! Vamos pedir uma receita...\")\n",
        "chef_brasileiro.print_response(\n",
        "    \"Me ensina a fazer um brigadeiro que fica cremoso!\", \n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎓 Agora vamos criar um Professor de Python\n",
        "\n",
        "professor_python = Agent(\n",
        "    model=Gemini(id=\"gemini-2.0-flash\"),\n",
        "    name=\"Professor Python\",\n",
        "    \n",
        "    description=\"Um professor didático e paciente de programação Python\",\n",
        "    \n",
        "    instructions=[\n",
        "        \"Você é um professor de Python experiente e muito didático\",\n",
        "        \"Explique conceitos complexos de forma simples\",\n",
        "        \"Use analogias do dia a dia para explicar programação\",\n",
        "        \"Sempre inclua exemplos práticos de código\",\n",
        "        \"Seja paciente e encorajador com iniciantes\",\n",
        "        \"Se o aluno errar, explique o erro de forma construtiva\",\n",
        "        \"Use emojis para deixar as explicações mais divertidas\"\n",
        "    ],\n",
        "    \n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "print(\"🎓 Professor Python pronto! Vamos fazer uma pergunta...\")\n",
        "professor_python.print_response(\n",
        "    \"Não entendi a diferença entre lista e dicionário em Python. Pode me explicar?\",\n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚙️ Configurações Avançadas - Ajustando o Motor\n\nLembra que falei que o modelo é como o motor do carro? Pois bem, agora vamos aprender a **ajustar esse motor**!\n\n### Principais Configurações:\n\n#### 🌡️ **Temperature** (0.0 - 2.0)\n- **0.0**: Robô super sério (sempre a mesma resposta)\n- **0.5**: Equilibrado (padrão)\n- **1.5**: Criativo maluco (respostas muito variadas)\n\n#### 📏 **Max Tokens**\n- Controla o tamanho máximo da resposta\n- 1 token ≈ 0.75 palavras em português\n\n#### 🎯 **Top P** (0.0 - 1.0)\n- Controla a diversidade de vocabulário\n- 0.1: Vocabulário limitado\n- 0.9: Vocabulário diverso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎨 Testando diferentes temperaturas\n",
        "\n",
        "# Agente CONSERVADOR (temperature=0.1)\n",
        "agente_conservador = Agent(\n",
        "    model=Gemini(\n",
        "        id=\"gemini-2.0-flash\",\n",
        "        temperature=0.1  # Bem conservador\n",
        "    ),\n",
        "    name=\"Agente Conservador\",\n",
        "    description=\"Um agente que sempre dá respostas consistentes\"\n",
        ")\n",
        "\n",
        "print(\"🤖 AGENTE CONSERVADOR (temp=0.1):\")\n",
        "agente_conservador.print_response(\"Conte uma piada sobre programadores\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Agente CRIATIVO (temperature=1.2)\n",
        "agente_criativo = Agent(\n",
        "    model=Gemini(\n",
        "        id=\"gemini-2.0-flash\",\n",
        "        temperature=1.2  # Bem criativo\n",
        "    ),\n",
        "    name=\"Agente Criativo\",\n",
        "    description=\"Um agente que sempre surpreende com criatividade\"\n",
        ")\n",
        "\n",
        "print(\"🎨 AGENTE CRIATIVO (temp=1.2):\")\n",
        "agente_criativo.print_response(\"Conte uma piada sobre programadores\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📏 Testando controle de tamanho (max_tokens)\n",
        "\n",
        "# Agente CONCISO\n",
        "agente_conciso = Agent(\n",
        "    model=Gemini(\n",
        "        id=\"gemini-2.0-flash\",\n",
        "        max_tokens=50  # Resposta bem curtinha\n",
        "    ),\n",
        "    name=\"Agente Conciso\",\n",
        "    instructions=[\"Seja sempre muito direto e conciso\"]\n",
        ")\n",
        "\n",
        "print(\"📝 AGENTE CONCISO (max_tokens=50):\")\n",
        "agente_conciso.print_response(\"Explique o que é inteligência artificial\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Agente DETALHADO\n",
        "agente_detalhado = Agent(\n",
        "    model=Gemini(\n",
        "        id=\"gemini-2.0-flash\",\n",
        "        max_tokens=300  # Resposta mais longa\n",
        "    ),\n",
        "    name=\"Agente Detalhado\",\n",
        "    instructions=[\"Seja sempre muito detalhado e didático\"]\n",
        ")\n",
        "\n",
        "print(\"📚 AGENTE DETALHADO (max_tokens=300):\")\n",
        "agente_detalhado.print_response(\"Explique o que é inteligência artificial\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎭 Context Engineering - A Arte dos Prompts Perfeitos\n\n**Context Engineering** é como ser um **diretor de cinema**. Você precisa dar o contexto perfeito para o ator (agente) fazer a performance ideal!\n\n### Os Elementos do Contexto:\n\n1. **System Message**: \"Você é...\"\n2. **User Message**: \"Faça isso...\"\n3. **Additional Context**: Informações extras\n4. **History**: Conversa anterior\n5. **Dependencies**: Dados externos\n\nÉ como montar um cenário completo para uma peça de teatro! 🎬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎬 Criando um agente com contexto rico\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "agente_contexto_rico = Agent(\n",
        "    model=Gemini(id=\"gemini-2.0-flash\"),\n",
        "    name=\"Assistente Pessoal Brasileiro\",\n",
        "    \n",
        "    # 🎭 Papel principal\n",
        "    description=\"Assistente pessoal brasileiro especializado em produtividade\",\n",
        "    \n",
        "    # 📝 Instruções detalhadas\n",
        "    instructions=[\n",
        "        \"Você é um assistente pessoal brasileiro muito eficiente\",\n",
        "        \"Você trabalha para executivos brasileiros\",\n",
        "        \"Sempre considere o fuso horário de Brasília\",\n",
        "        \"Seja proativo e sugira melhorias\",\n",
        "        \"Use linguagem profissional mas amigável\",\n",
        "        \"Quando der horários, sempre mencione se é manhã/tarde/noite\"\n",
        "    ],\n",
        "    \n",
        "    # 🕒 Contexto temporal\n",
        "    add_datetime_to_context=True,\n",
        "    \n",
        "    # 🏷️ Nome no contexto\n",
        "    add_name_to_context=True,\n",
        "    \n",
        "    # 📍 Localização (simulada)\n",
        "    add_location_to_context=True,\n",
        "    \n",
        "    # 📄 Contexto adicional\n",
        "    additional_context=\"\"\"\n",
        "    Informações importantes:\n",
        "    - Hoje é um dia útil\n",
        "    - O usuário está no Brasil (GMT-3)\n",
        "    - Prefere reuniões pela manhã\n",
        "    - Tem almoço sempre às 12h\n",
        "    \"\"\",\n",
        "    \n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "print(\"🎬 Agente com contexto rico criado!\")\n",
        "agente_contexto_rico.print_response(\n",
        "    \"Preciso agendar uma reunião importante. Que horários você sugere?\",\n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔄 Comparando Diferentes Modelos\n\nAgora vamos fazer um **teste prático** comparando diferentes configurações! É como testar diferentes carros na mesma pista. 🏁\n\n**Dica!** 💡 Na vida real, você testaria GPT vs Claude vs Gemini, mas para economizar, vamos testar diferentes configurações do Gemini mesmo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🏁 Competição de Agentes: Qual é o melhor?\n",
        "\n",
        "# Desafio: \"Escreva um email profissional pedindo aumento\"\n",
        "desafio = \"Escreva um email profissional para meu chefe pedindo aumento de salário. Trabalho há 2 anos na empresa como desenvolvedor Python.\"\n",
        "\n",
        "print(\"🏁 COMPETIÇÃO DE AGENTES!\")\n",
        "print(f\"Desafio: {desafio}\")\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# 🤖 Competidor 1: Agente Formal\n",
        "agente_formal = Agent(\n",
        "    model=Gemini(id=\"gemini-2.0-flash\", temperature=0.3),\n",
        "    name=\"Agente Formal\",\n",
        "    instructions=[\n",
        "        \"Seja extremamente profissional e formal\",\n",
        "        \"Use linguagem corporativa tradicional\",\n",
        "        \"Seja direto e objetivo\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"👔 AGENTE FORMAL (temp=0.3):\")\n",
        "agente_formal.print_response(desafio)\n",
        "\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# 🤖 Competidor 2: Agente Humano\n",
        "agente_humano = Agent(\n",
        "    model=Gemini(id=\"gemini-2.0-flash\", temperature=0.7),\n",
        "    name=\"Agente Humano\",\n",
        "    instructions=[\n",
        "        \"Seja profissional mas humano\", \n",
        "        \"Use tom pessoal sem perder o profissionalismo\",\n",
        "        \"Mostre valor de forma convincente mas humilde\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"😊 AGENTE HUMANO (temp=0.7):\")\n",
        "agente_humano.print_response(desafio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Exercício Prático - Criando Seu Agente Especializado\n\nAgora é sua vez! Vamos criar um agente especializado do zero. Escolha uma das opções abaixo (ou invente uma!):\n\n### 🎨 Opções de Agentes:\n1. **Personal Trainer Virtual** - Monta treinos personalizados\n2. **Consultor de Investimentos** - Dá dicas de finanças pessoais  \n3. **Coach de Carreira** - Ajuda com currículos e entrevistas\n4. **Nutricionista Digital** - Cria dietas saudáveis\n5. **Professor de Inglês** - Ensina inglês conversacional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 SEU TURNO: Crie seu agente especializado aqui!\n",
        "\n",
        "# Exemplo: Personal Trainer Virtual\n",
        "meu_agente_especializado = Agent(\n",
        "    model=Gemini(\n",
        "        id=\"gemini-2.0-flash\",\n",
        "        temperature=0.6,  # Ajuste conforme necessário\n",
        "        max_tokens=400    # Ajuste conforme necessário\n",
        "    ),\n",
        "    \n",
        "    name=\"Personal Trainer Virtual\",  # Mude para sua escolha\n",
        "    \n",
        "    description=\"Personal trainer motivador especializado em treinos caseiros\",\n",
        "    \n",
        "    instructions=[\n",
        "        # Coloque suas instruções aqui!\n",
        "        \"Você é um personal trainer experiente e motivador\",\n",
        "        \"Foque em exercícios que podem ser feitos em casa\",\n",
        "        \"Sempre pergunte sobre limitações físicas\",\n",
        "        \"Seja encorajador e positivo\",\n",
        "        \"Use linguagem motivacional mas não exagerada\",\n",
        "        \"Sugira sempre alternativas para diferentes níveis\"\n",
        "    ],\n",
        "    \n",
        "    additional_context=\"\"\"\n",
        "    Informações importantes:\n",
        "    - Prefira exercícios sem equipamentos\n",
        "    - Considere que a pessoa pode ser iniciante\n",
        "    - Sempre inclua aquecimento e alongamento\n",
        "    \"\"\",\n",
        "    \n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "# Teste seu agente!\n",
        "print(\"🎯 Testando seu agente especializado:\")\n",
        "meu_agente_especializado.print_response(\n",
        "    \"Oi! Sou iniciante e quero começar a me exercitar em casa. Você pode me ajudar?\",\n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔍 Análise de Performance - Métricas que Importam\n\nQuando você cria agentes para produção, precisa **medir** se eles estão performando bem. É como acompanhar o desempenho de um atleta! 📊\n\n### Métricas Importantes:\n\n1. **Tempo de Resposta**: Quanto tempo demora?\n2. **Tokens Usados**: Quanto está custando?\n3. **Qualidade da Resposta**: Está respondendo bem?\n4. **Consistência**: As respostas são consistentes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 Medindo performance dos nossos agentes\n",
        "\n",
        "import time\n",
        "\n",
        "def testar_performance(agente, pergunta, nome_agente):\n",
        "    \"\"\"Testa a performance de um agente\"\"\"\n",
        "    print(f\"\\n🧪 Testando: {nome_agente}\")\n",
        "    print(f\"Pergunta: {pergunta}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Medir tempo\n",
        "    inicio = time.time()\n",
        "    \n",
        "    # Executar agente\n",
        "    resposta = agente.run(pergunta)\n",
        "    \n",
        "    # Calcular tempo\n",
        "    tempo_total = time.time() - inicio\n",
        "    \n",
        "    # Mostrar métricas\n",
        "    print(f\"\\n📊 MÉTRICAS:\")\n",
        "    print(f\"⏱️ Tempo: {tempo_total:.2f} segundos\")\n",
        "    print(f\"📝 Tamanho da resposta: {len(resposta.content)} caracteres\")\n",
        "    \n",
        "    # Mostrar resposta\n",
        "    print(f\"\\n💬 RESPOSTA:\")\n",
        "    print(resposta.content)\n",
        "    \n",
        "    return tempo_total, len(resposta.content)\n",
        "\n",
        "# Pergunta padrão para testar\n",
        "pergunta_teste = \"Explique em 2 parágrafos o que é machine learning\"\n",
        "\n",
        "# Teste com diferentes configurações\n",
        "agente_rapido = Agent(\n",
        "    model=Gemini(id=\"gemini-2.0-flash\", temperature=0.1),\n",
        "    name=\"Agente Rápido\",\n",
        "    instructions=[\"Seja conciso e direto\"]\n",
        ")\n",
        "\n",
        "agente_detalhado = Agent(\n",
        "    model=Gemini(id=\"gemini-2.0-flash\", temperature=0.5),\n",
        "    name=\"Agente Detalhado\", \n",
        "    instructions=[\"Seja detalhado e didático\"]\n",
        ")\n",
        "\n",
        "# Executar testes\n",
        "tempo1, tamanho1 = testar_performance(agente_rapido, pergunta_teste, \"Agente Rápido\")\n",
        "tempo2, tamanho2 = testar_performance(agente_detalhado, pergunta_teste, \"Agente Detalhado\")\n",
        "\n",
        "print(\"\\n🏆 RESUMO DA COMPARAÇÃO:\")\n",
        "print(f\"Agente Rápido: {tempo1:.2f}s, {tamanho1} chars\")\n",
        "print(f\"Agente Detalhado: {tempo2:.2f}s, {tamanho2} chars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📈 Visualizando Dados dos Nossos Agentes\n\nQue tal criar uns gráficos para visualizar a performance? Dados são mais claros quando visualizados! 📊"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 Gráfico de comparação de performance\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dados simulados de diferentes configurações\n",
        "configuracoes = ['Temp 0.1\\n(Conservador)', 'Temp 0.5\\n(Balanceado)', 'Temp 1.0\\n(Criativo)']\n",
        "tempo_resposta = [1.2, 1.8, 2.1]  # segundos\n",
        "tamanho_resposta = [150, 280, 350]  # caracteres\n",
        "criatividade = [3, 7, 9]  # escala 1-10\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Gráfico 1: Tempo de Resposta\n",
        "cores = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "ax1.bar(configuracoes, tempo_resposta, color=cores)\n",
        "ax1.set_title('⏱️ Tempo de Resposta', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Segundos')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Tamanho da Resposta\n",
        "ax2.bar(configuracoes, tamanho_resposta, color=cores)\n",
        "ax2.set_title('📝 Tamanho da Resposta', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Caracteres')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Gráfico 3: Nível de Criatividade\n",
        "ax3.bar(configuracoes, criatividade, color=cores)\n",
        "ax3.set_title('🎨 Nível de Criatividade', fontsize=14, fontweight='bold')\n",
        "ax3.set_ylabel('Escala 1-10')\n",
        "ax3.set_ylim(0, 10)\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('🤖 Comparação de Performance dos Agentes', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n📊 Como interpretar:\")\n",
        "print(\"• Menor temperatura = Mais rápido, mais consistente, menos criativo\")\n",
        "print(\"• Maior temperatura = Mais lento, respostas maiores, mais criativo\")\n",
        "print(\"• Escolha baseada no seu caso de uso! 🎯\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔄 Fluxo de Context Engineering\n\nVamos visualizar como funciona o **Context Engineering** - o processo de construir o contexto perfeito para nossos agentes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔄 Visualizando o fluxo de Context Engineering\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Dados do fluxo\n",
        "etapas = [\n",
        "    'Sistema\\n(Papel)',\n",
        "    'Instruções\\n(Como agir)',\n",
        "    'Contexto\\n(Informações)',\n",
        "    'Input\\n(Pergunta)',\n",
        "    'Processamento\\n(LLM)',\n",
        "    'Output\\n(Resposta)'\n",
        "]\n",
        "\n",
        "posicoes_x = [1, 2.5, 4, 5.5, 7, 8.5]\n",
        "posicoes_y = [4, 4, 4, 4, 4, 4]\n",
        "\n",
        "cores = ['#FF6B6B', '#FFA07A', '#FFD700', '#98FB98', '#87CEEB', '#DDA0DD']\n",
        "\n",
        "# Desenhar as caixas\n",
        "for i, (etapa, x, y, cor) in enumerate(zip(etapas, posicoes_x, posicoes_y, cores)):\n",
        "    # Caixa principal\n",
        "    bbox = FancyBboxPatch(\n",
        "        (x-0.4, y-0.3), 0.8, 0.6,\n",
        "        boxstyle=\"round,pad=0.05\",\n",
        "        facecolor=cor,\n",
        "        edgecolor='black',\n",
        "        linewidth=2\n",
        "    )\n",
        "    ax.add_patch(bbox)\n",
        "    \n",
        "    # Texto\n",
        "    ax.text(x, y, etapa, ha='center', va='center', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    # Setas\n",
        "    if i < len(etapas) - 1:\n",
        "        ax.annotate('', xy=(posicoes_x[i+1]-0.4, y), xytext=(x+0.4, y),\n",
        "                   arrowprops=dict(arrowstyle='->', lw=2, color='black'))\n",
        "\n",
        "# Configurações do gráfico\n",
        "ax.set_xlim(0, 10)\n",
        "ax.set_ylim(2, 6)\n",
        "ax.set_title('🔄 Fluxo de Context Engineering no Agno', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.axis('off')\n",
        "\n",
        "# Adicionar exemplos embaixo\n",
        "exemplos = [\n",
        "    '\"Você é um\\nchef brasileiro\"',\n",
        "    '\"Fale de forma\\ncalorosa\"',\n",
        "    '\"Usuário gosta\\nde comida caseira\"',\n",
        "    '\"Receita de\\nbrigadeiro\"',\n",
        "    '🧠 Gemini\\nprocessa',\n",
        "    '\"Oi meu querido...\\naqui está a receita!\"'\n",
        "]\n",
        "\n",
        "for i, (exemplo, x) in enumerate(zip(exemplos, posicoes_x)):\n",
        "    ax.text(x, 2.8, exemplo, ha='center', va='center', fontsize=8, \n",
        "           style='italic', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n🎯 Lição importante:\")\n",
        "print(\"Context Engineering é como dirigir um carro - quanto melhor você configurar,\")\n",
        "print(\"melhor será a performance! Cada parte importa para o resultado final. 🚗💨\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Desafio Final - Sistema de Agentes Especialistas\n\nAgora vamos criar um **sistema com múltiplos agentes especialistas**! Cada um com sua especialidade e configuração otimizada.\n\nÉ como montar uma equipe de especialistas para resolver diferentes problemas! 👥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 Sistema de Agentes Especialistas\n",
        "\n",
        "class SistemaAgentesEspecialistas:\n",
        "    def __init__(self):\n",
        "        # 💼 Agente de Negócios\n",
        "        self.agente_negocios = Agent(\n",
        "            model=Gemini(id=\"gemini-2.0-flash\", temperature=0.3),\n",
        "            name=\"Consultor de Negócios\",\n",
        "            instructions=[\n",
        "                \"Você é um consultor de negócios sênior\",\n",
        "                \"Foque em estratégia, ROI e crescimento\", \n",
        "                \"Seja prático e objetivo\",\n",
        "                \"Use dados e exemplos reais\"\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # 🎨 Agente Criativo\n",
        "        self.agente_criativo = Agent(\n",
        "            model=Gemini(id=\"gemini-2.0-flash\", temperature=1.1),\n",
        "            name=\"Diretor Criativo\",\n",
        "            instructions=[\n",
        "                \"Você é um diretor criativo inovador\",\n",
        "                \"Pense fora da caixa\",\n",
        "                \"Gere ideias únicas e impactantes\",\n",
        "                \"Use analogias criativas\"\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # 🔧 Agente Técnico\n",
        "        self.agente_tecnico = Agent(\n",
        "            model=Gemini(id=\"gemini-2.0-flash\", temperature=0.2),\n",
        "            name=\"Arquiteto Técnico\",\n",
        "            instructions=[\n",
        "                \"Você é um arquiteto técnico experiente\",\n",
        "                \"Foque em implementação e viabilidade\",\n",
        "                \"Seja preciso e detalhado\",\n",
        "                \"Considere sempre escalabilidade e segurança\"\n",
        "            ]\n",
        "        )\n",
        "    \n",
        "    def consultar_especialistas(self, problema):\n",
        "        \"\"\"Consulta todos os especialistas sobre um problema\"\"\"\n",
        "        print(f\"🎯 PROBLEMA: {problema}\")\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        \n",
        "        # Consulta cada especialista\n",
        "        print(\"\\n💼 VISÃO DE NEGÓCIOS:\")\n",
        "        self.agente_negocios.print_response(problema)\n",
        "        \n",
        "        print(\"\\n🎨 VISÃO CRIATIVA:\")\n",
        "        self.agente_criativo.print_response(problema)\n",
        "        \n",
        "        print(\"\\n🔧 VISÃO TÉCNICA:\")\n",
        "        self.agente_tecnico.print_response(problema)\n",
        "\n",
        "# Criar o sistema\n",
        "sistema = SistemaAgentesEspecialistas()\n",
        "\n",
        "# Teste com um problema real\n",
        "problema = \"Como criar um aplicativo de delivery de comida que se diferencie dos concorrentes?\"\n",
        "\n",
        "sistema.consultar_especialistas(problema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏁 Resumo do Módulo - O que Aprendemos\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/agno-2.0-framework--modulo-02_img_02.png)\n\n**Liiindo!** 🎉 Você chegou ao final do Módulo 2! Vamos recapitular o que rolou:\n\n## 🧠 Conceitos Dominados:\n\n### 1. **Modelos LLM** 🤖\n- ✅ Entendemos que são o \"motor\" dos agentes\n- ✅ Conhecemos GPT, Claude, Gemini e suas diferenças\n- ✅ Aprendemos a escolher o modelo certo para cada caso\n\n### 2. **Configurações de Modelo** ⚙️\n- ✅ **Temperature**: Controla criatividade (0.0-2.0)\n- ✅ **Max Tokens**: Limita tamanho das respostas\n- ✅ **Top P**: Controla diversidade de vocabulário\n\n### 3. **Instruções e Roles** 🎭\n- ✅ Como \"programar\" a personalidade dos agentes\n- ✅ Estrutura: Papel + Contexto + Objetivo + Tom + Restrições\n- ✅ Criamos chefs, professores, consultores...\n\n### 4. **Context Engineering** 🎬\n- ✅ Arte de construir o contexto perfeito\n- ✅ System Message + Instructions + Additional Context\n- ✅ Como diferentes contextos geram diferentes resultados\n\n### 5. **Performance e Métricas** 📊\n- ✅ Como medir tempo, tokens, qualidade\n- ✅ Comparar diferentes configurações\n- ✅ Otimizar para casos específicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Preparando para o Próximo Módulo\n\nNo **Módulo 3**, vamos dar **superpoderes** aos nossos agentes com **Ferramentas e Tools**! 🛠️\n\n### O que vem por aí:\n- 🌐 **Web Search**: Agentes que pesquisam na internet\n- 📰 **HackerNews**: Buscar notícias de tecnologia\n- 🛠️ **Tools Customizadas**: Criar suas próprias ferramentas\n- 🔌 **Integrações**: APIs, bancos de dados, serviços externos\n\n## 💡 Dicas para Praticar:\n\n1. **Experimente diferentes temperatures** no mesmo agente\n2. **Crie agentes com personalidades distintas**\n3. **Teste várias instruções** para o mesmo objetivo\n4. **Meça a performance** das suas configurações\n5. **Compare resultados** entre diferentes modelos\n\n## 🎯 Exercício para Casa:\n\nCrie **3 agentes diferentes** para o mesmo problema, mas com:\n- Temperatures diferentes (0.2, 0.7, 1.2)\n- Instruções diferentes (formal, casual, técnico)\n- Compare os resultados!\n\n---\n\n**Parabéns!** 🏆 Você agora entende como funciona o **cérebro dos agentes de IA**. No próximo módulo, vamos dar **ferramentas** para eles interagirem com o mundo real!\n\n**Bora para o Módulo 3!** 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎊 Célula de Celebração!\n",
        "\n",
        "print(\"🎉\" * 50)\n",
        "print(\"\\n\" + \" \" * 15 + \"PARABÉNS! MÓDULO 2 CONCLUÍDO!\")\n",
        "print(\"\\n\" + \" \" * 10 + \"Você agora sabe como configurar agentes como um PRO!\")\n",
        "print(\"\\n\" + \" \" * 18 + \"Próximo: Módulo 3 - Tools! 🛠️\")\n",
        "print(\"\\n\" + \"🎉\" * 50)\n",
        "\n",
        "# Estatísticas do que foi aprendido\n",
        "conceitos_aprendidos = [\n",
        "    \"✅ Modelos LLM (GPT, Claude, Gemini)\",\n",
        "    \"✅ Configurações (Temperature, Tokens, Top-P)\", \n",
        "    \"✅ Instructions e Role Engineering\",\n",
        "    \"✅ Context Engineering\",\n",
        "    \"✅ Performance e Métricas\",\n",
        "    \"✅ Sistema Multi-Agentes\"\n",
        "]\n",
        "\n",
        "print(\"\\n📚 CONCEITOS DOMINADOS:\")\n",
        "for conceito in conceitos_aprendidos:\n",
        "    print(f\"  {conceito}\")\n",
        "\n",
        "print(\"\\n🚀 PRÓXIMA AVENTURA: Módulo 3 - Ferramentas e Tools!\")\n",
        "print(\"   Os agentes vão aprender a usar a internet, APIs e muito mais!\")"
      ]
    }
  ]
}
